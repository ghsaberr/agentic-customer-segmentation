{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7d07282-ebc8-4df4-98a2-07f036462247",
   "metadata": {},
   "source": [
    "# Agentic Customer Segmentation for Targeted Marketing\n",
    "Build a segmentation pipeline and a local LLM-backed agent that explains clusters, retrieves grounding docs, and drafts targeted messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7fa7a9a-aa3d-4f54-99d1-75cfbb24dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_insurance_dataset_realistic_v3(\n",
    "    n_customers: int = 5000,\n",
    "    start_date: str = \"2020-01-01\",\n",
    "    end_date: str = \"2024-12-31\",\n",
    "    seed: int = 42,\n",
    "    correlation_strength: float = 0.6,\n",
    "    return_metadata: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Version 3 — Robust & Realistic Synthetic Insurance Dataset Generator\n",
    "\n",
    "    Key improvements vs v2:\n",
    "    - Removed target leakage (renewal_prob, LTV independent from direct targets)\n",
    "    - Vectorized operations for speed\n",
    "    - Guaranteed valid date intervals\n",
    "    - Correlated age–income with configurable strength\n",
    "    - Realistic churn, claim, and premium dynamics\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    correlation_strength = np.clip(correlation_strength, 0.0, 0.95)\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "\n",
    "    # --- 1. Demographics (age–income correlation)\n",
    "    mean = [0, 0]\n",
    "    cov = [[1, correlation_strength], [correlation_strength, 1]]\n",
    "    z_age, z_income = rng.multivariate_normal(mean, cov, n_customers).T\n",
    "\n",
    "    ages = np.clip((z_age * 12 + 45).astype(int), 18, 85)\n",
    "    income_levels = np.exp(z_income * 0.3) * (25000 + 600 * ages)\n",
    "    income_levels *= rng.lognormal(0, 0.2, n_customers)\n",
    "    income_levels = np.clip(income_levels, 20000, 250000)\n",
    "\n",
    "    genders = rng.choice([\"M\", \"F\"], n_customers, p=[0.52, 0.48])\n",
    "    regions = rng.choice([\"Urban\", \"Suburban\", \"Rural\"], n_customers, p=[0.4, 0.45, 0.15])\n",
    "\n",
    "    # --- 2. Policy Type (income-driven probability)\n",
    "    income_scaled = (income_levels - income_levels.min()) / (income_levels.max() - income_levels.min())\n",
    "    policy_probs = np.vstack([\n",
    "        np.clip([\n",
    "            0.55 - 0.10 * income_scaled,\n",
    "            0.25 + 0.10 * income_scaled,\n",
    "            0.10 + 0.08 * income_scaled,\n",
    "            0.10\n",
    "        ], 0, None).T for _ in range(1)\n",
    "    ]).reshape(n_customers, 4)\n",
    "    policy_probs /= policy_probs.sum(axis=1, keepdims=True)\n",
    "    policy_types = np.array([\"Auto\", \"Home\", \"Life\", \"Health\"])\n",
    "    chosen_policy = [rng.choice(policy_types, p=p) for p in policy_probs]\n",
    "\n",
    "    # --- 3. Premium Amounts (policy + income)\n",
    "    base_premiums = {\"Auto\": 800, \"Home\": 1600, \"Life\": 2000, \"Health\": 1200}\n",
    "    premium_base = np.array([base_premiums[p] for p in chosen_policy])\n",
    "    premium_amount = premium_base * (1 + np.sqrt(income_levels / 150000) * 0.5)\n",
    "    premium_amount *= rng.lognormal(0, 0.25, n_customers)\n",
    "    premium_amount = np.clip(premium_amount, 300, 10000)\n",
    "\n",
    "    # --- 4. Policy tenure (valid date intervals)\n",
    "    tenure_months = np.clip(rng.exponential(30, n_customers), 3, 84)\n",
    "    tenure_days = (tenure_months * 30).astype(int)\n",
    "    valid_start_days = np.maximum(1, (end - start).days - tenure_days)\n",
    "    start_offsets = rng.integers(0, valid_start_days, n_customers)\n",
    "    policy_start_dates = start + pd.to_timedelta(start_offsets, unit=\"D\")\n",
    "    policy_end_dates = policy_start_dates + pd.to_timedelta(tenure_days, unit=\"D\")\n",
    "    policy_end_dates = policy_end_dates.clip(upper=end)\n",
    "\n",
    "    # --- 5. Payment behavior\n",
    "    payment_freq = rng.choice([\"Monthly\", \"Quarterly\", \"Annual\"], n_customers, p=[0.6, 0.25, 0.15])\n",
    "    payment_regularity = np.clip(rng.beta(4, 1.5, n_customers) + rng.normal(0, 0.05, n_customers), 0.3, 1.0)\n",
    "\n",
    "    # --- 6. Claims (rate depends on age + policy)\n",
    "    base_claim_rate = np.where(ages < 25, 0.25, np.where(ages > 65, 0.18, 0.1))\n",
    "    policy_factor = np.array([{\"Auto\":1.4, \"Home\":0.8, \"Life\":0.6, \"Health\":1.0}[p] for p in chosen_policy])\n",
    "    claim_lambda = base_claim_rate * policy_factor * np.sqrt(tenure_months / 12)\n",
    "    num_claims = np.clip(rng.poisson(claim_lambda), 0, 15)\n",
    "\n",
    "    # Claim costs — lognormal by policy type\n",
    "    claim_cost_params = {\"Auto\": (7.8, 0.9), \"Home\": (8.3, 0.8), \"Life\": (9.0, 0.6), \"Health\": (8.0, 1.0)}\n",
    "    claim_costs = np.zeros(n_customers)\n",
    "    for p, (mean, sigma) in claim_cost_params.items():\n",
    "        idx = np.array(chosen_policy) == p\n",
    "        claim_costs[idx] = num_claims[idx] * rng.lognormal(mean, sigma, idx.sum())\n",
    "\n",
    "    # --- 7. Renewal probability (independent from direct LTV)\n",
    "    logits = (\n",
    "        -0.02 * (ages - 45)\n",
    "        - 0.3 * num_claims\n",
    "        + 1.0 * payment_regularity\n",
    "        + 0.004 * tenure_months\n",
    "        + rng.normal(0, 0.5, n_customers)\n",
    "    )\n",
    "    renewal_prob = 1 / (1 + np.exp(-logits))\n",
    "    renewal_prob = np.clip(renewal_prob, 0.05, 0.95)\n",
    "    churned = rng.binomial(1, 1 - renewal_prob)\n",
    "\n",
    "    # --- 8. Last claim date (only for claimants)\n",
    "    has_claims = num_claims > 0\n",
    "    last_claim_date = np.full(n_customers, np.datetime64(\"NaT\"), dtype=\"datetime64[ns]\")\n",
    "    random_offsets = rng.exponential(180, has_claims.sum()).astype(int)\n",
    "    temp_dates = policy_end_dates[has_claims] - pd.to_timedelta(random_offsets, unit=\"D\")\n",
    "    temp_dates = np.maximum(temp_dates.values.astype(\"datetime64[D]\"), policy_start_dates[has_claims].values.astype(\"datetime64[D]\"))\n",
    "    last_claim_date[has_claims] = temp_dates\n",
    "\n",
    "    # --- 9. Lifetime Value (LTV — derived from financial signals only)\n",
    "    expected_value = premium_amount * (tenure_months / 12)\n",
    "    claim_penalty = np.minimum(claim_costs / (expected_value + 1e-6), 0.8)\n",
    "    ltv = expected_value * (1 - claim_penalty) * (0.8 + 0.4 * renewal_prob)\n",
    "    ltv[churned == 1] *= rng.uniform(0.4, 0.8, churned.sum())\n",
    "    ltv = np.clip(ltv, 0, 250_000)\n",
    "\n",
    "    # --- 10. Derived temporal features\n",
    "    policy_age_days = (policy_end_dates - policy_start_dates).dt.days\n",
    "    days_since_last_claim = (policy_end_dates - last_claim_date).dt.days\n",
    "    days_since_last_claim[~has_claims] = np.nan\n",
    "    is_active = (policy_end_dates >= end).astype(int)\n",
    "\n",
    "    # --- 11. Final DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"customer_id\": [f\"CUST_{i:05d}\" for i in range(1, n_customers + 1)],\n",
    "        \"age\": ages,\n",
    "        \"gender\": genders,\n",
    "        \"region\": regions,\n",
    "        \"income_level\": np.round(income_levels, 2),\n",
    "        \"policy_type\": chosen_policy,\n",
    "        \"premium_amount\": np.round(premium_amount, 2),\n",
    "        \"payment_frequency\": payment_freq,\n",
    "        \"payment_regularity\": np.round(payment_regularity, 3),\n",
    "        \"tenure_months\": np.round(tenure_months, 1),\n",
    "        \"num_claims\": num_claims,\n",
    "        \"claim_costs\": np.round(claim_costs, 2),\n",
    "        \"policy_start_date\": policy_start_dates,\n",
    "        \"policy_end_date\": policy_end_dates,\n",
    "        \"last_claim_date\": pd.to_datetime(last_claim_date),\n",
    "        \"renewal_probability\": np.round(renewal_prob, 3),\n",
    "        \"churned\": churned,\n",
    "        \"customer_ltv\": np.round(ltv, 2),\n",
    "        \"policy_age_days\": policy_age_days,\n",
    "        \"days_since_last_claim\": days_since_last_claim,\n",
    "        \"is_active\": is_active,\n",
    "    })\n",
    "\n",
    "    if return_metadata:\n",
    "        metadata = {\n",
    "            \"n_customers\": n_customers,\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"seed\": seed,\n",
    "            \"correlation_strength\": correlation_strength,\n",
    "            \"generated_on\": pd.Timestamp.now().isoformat(),\n",
    "        }\n",
    "        return df, metadata\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc2b919-5846-466d-b8da-7b06d20df3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_with_engagement_and_flags_v3(df: pd.DataFrame, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ✅ Version 3 — Realistic augmentation of insurance dataset with engagement, delinquency, and risk flags.\n",
    "    \n",
    "    Key improvements:\n",
    "    - No leakage from churn/renewal into behavior features.\n",
    "    - Behavioral realism: digital users (younger, urban, higher income) show more engagement.\n",
    "    - Payment and claim behaviors influence risk/delinquency flags probabilistically.\n",
    "    - Adds derived scores and flags used for segmentation.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    df = df.copy()\n",
    "\n",
    "    # --- 1. Engagement behavior (portal logins, calls, emails)\n",
    "    # Digital affinity by region & age\n",
    "    digital_affinity = (\n",
    "        0.6 * (df[\"region\"] == \"Urban\").astype(float)\n",
    "        + 0.3 * (df[\"region\"] == \"Suburban\").astype(float)\n",
    "        + 0.1 * (df[\"region\"] == \"Rural\").astype(float)\n",
    "    )\n",
    "    digital_affinity *= np.clip((70 - df[\"age\"]) / 40, 0, 1)  # Younger = more digital\n",
    "    digital_affinity *= np.clip(np.log1p(df[\"income_level\"]) / np.log(150_000), 0.6, 1.2)\n",
    "\n",
    "    # Engagement base (mean ~ digital_affinity × tenure)\n",
    "    base_logins = 3 + 15 * digital_affinity + 0.05 * df[\"tenure_months\"]\n",
    "    portal_logins = np.clip(rng.normal(base_logins, 2), 0, None).astype(int)\n",
    "\n",
    "    # Support calls (older + rural → more)\n",
    "    support_calls = np.clip(\n",
    "        rng.poisson(1 + 0.015 * (df[\"age\"] - 30) + 1.5 * (df[\"region\"] == \"Rural\").astype(int)),\n",
    "        0,\n",
    "        15,\n",
    "    )\n",
    "\n",
    "    # Emails opened (proportional to digital use)\n",
    "    emails_opened = np.clip(rng.poisson(10 * digital_affinity + 2), 0, 50)\n",
    "\n",
    "    # --- 2. Payment delinquency\n",
    "    base_delinquency_prob = (\n",
    "        0.04 + 0.08 * (df[\"payment_regularity\"] < 0.8).astype(float)\n",
    "        + 0.03 * (df[\"income_level\"] < 40_000).astype(float)\n",
    "        + 0.02 * (df[\"policy_type\"] == \"Auto\").astype(float)\n",
    "    )\n",
    "    delinquency_count = rng.binomial(n=3, p=np.clip(base_delinquency_prob, 0, 0.8))\n",
    "\n",
    "    # --- 3. Engagement score (normalized composite)\n",
    "    max_portal, max_emails, max_calls = (\n",
    "        portal_logins.max(),\n",
    "        emails_opened.max(),\n",
    "        support_calls.max(),\n",
    "    )\n",
    "    engagement_score = (\n",
    "        0.5 * (portal_logins / (max_portal + 1e-5))\n",
    "        + 0.3 * (emails_opened / (max_emails + 1e-5))\n",
    "        + 0.2 * (1 - support_calls / (max_calls + 1e-5))\n",
    "    )\n",
    "    engagement_score = np.clip(engagement_score, 0, 1)\n",
    "\n",
    "    # --- 4. Risk flags (no leakage)\n",
    "    # High claim frequency/severity → high risk\n",
    "    claim_freq_flag = (df[\"num_claims\"] > 3).astype(int)\n",
    "    high_claim_cost_flag = (df[\"claim_costs\"] > df[\"claim_costs\"].median() * 2).astype(int)\n",
    "\n",
    "    # Financial risk from delinquency\n",
    "    payment_risk_flag = (delinquency_count >= 2).astype(int)\n",
    "\n",
    "    # Behavior risk (low engagement)\n",
    "    low_engagement_flag = (engagement_score < 0.3).astype(int)\n",
    "\n",
    "    # --- 5. Lifecycle and product mix\n",
    "    # Simple heuristic: stage inferred from tenure\n",
    "    lifecycle_stage = pd.cut(\n",
    "        df[\"tenure_months\"],\n",
    "        bins=[0, 12, 36, 72, np.inf],\n",
    "        labels=[\"New\", \"Growth\", \"Mature\", \"Legacy\"],\n",
    "        right=False,\n",
    "    )\n",
    "\n",
    "    # Product mix: probability of having another product (income + engagement)\n",
    "    multi_policy_prob = np.clip(0.1 + 0.001 * (df[\"income_level\"] / 1000) + 0.3 * engagement_score, 0, 0.9)\n",
    "    multi_policy_flag = rng.binomial(1, multi_policy_prob)\n",
    "\n",
    "    # --- 6. Engagement trends (rolling proxy)\n",
    "    recent_logins_3m = np.clip(\n",
    "        (portal_logins * rng.uniform(0.6, 1.0, len(df))).astype(int),\n",
    "        0,\n",
    "        portal_logins,\n",
    "    )\n",
    "    engagement_trend = np.where(\n",
    "        recent_logins_3m > (0.8 * portal_logins), \"Up\",\n",
    "        np.where(recent_logins_3m < (0.5 * portal_logins), \"Down\", \"Stable\")\n",
    "    )\n",
    "\n",
    "    # --- 7. Add all columns\n",
    "    df[\"portal_logins\"] = portal_logins\n",
    "    df[\"support_calls\"] = support_calls\n",
    "    df[\"emails_opened\"] = emails_opened\n",
    "    df[\"delinquency_count\"] = delinquency_count\n",
    "    df[\"engagement_score\"] = np.round(engagement_score, 3)\n",
    "    df[\"claim_freq_flag\"] = claim_freq_flag\n",
    "    df[\"high_claim_cost_flag\"] = high_claim_cost_flag\n",
    "    df[\"payment_risk_flag\"] = payment_risk_flag\n",
    "    df[\"low_engagement_flag\"] = low_engagement_flag\n",
    "    df[\"multi_policy_flag\"] = multi_policy_flag\n",
    "    df[\"lifecycle_stage\"] = lifecycle_stage\n",
    "    df[\"engagement_trend\"] = engagement_trend\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abe0a38-a2aa-4de9-92d7-6cbdc7b84bad",
   "metadata": {},
   "source": [
    "#### Engagement & Behavioral Augmentation\n",
    "\n",
    "In this step, we extend the core insurance dataset with behavioral and risk-oriented features.\n",
    "The augmentation focuses on *realistic but non-leaky* signals that reflect how customers interact\n",
    "with digital platforms, payment schedules, and policy services.\n",
    "\n",
    "**Highlights**\n",
    "- No target leakage from churn or renewal into engagement metrics.\n",
    "- Behavioral realism: younger, urban customers are more digitally engaged.\n",
    "- Risk flags derived from independent probabilistic logic.\n",
    "- Added lifecycle and engagement trend indicators to support clustering.\n",
    "\n",
    "We'll use these features to drive segmentation and interpret customer clusters\n",
    "in later stages of the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f948aaaa-58a3-4ce6-b3f9-573e1fd0f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import uuid\n",
    "from datetime import timedelta\n",
    "from textwrap import shorten\n",
    "\n",
    "def generate_document_corpus_v2(\n",
    "    customers_df: pd.DataFrame = None,\n",
    "    n_docs: int = 60,\n",
    "    start_date: str = \"2020-01-01\",\n",
    "    end_date: str = \"2024-12-31\",\n",
    "    seed: int = 42,\n",
    "    verbose: bool = False,\n",
    "    max_passage_words: int = 200,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate a synthetic document corpus aligned with a customer/policy dataset.\n",
    "\n",
    "    Features:\n",
    "      - Optional linking to customers_df: attaches policy_id / customer_id where relevant\n",
    "      - Category/subtype normalized across all docs\n",
    "      - created_date sampled between start_date and end_date (can align to policy dates)\n",
    "      - Topic-aware keywords and longer contextual text for better retrieval\n",
    "      - Passage splitting (if text long) and stable doc_id / passage_id scheme\n",
    "      - Returns DataFrame ready for embedding + indexing with metadata fields:\n",
    "        ['doc_id', 'passage_id', 'policy_id', 'customer_id', 'category', 'subtype',\n",
    "         'source', 'created_date', 'text', 'keywords']\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    start = pd.to_datetime(start_date)\n",
    "    end = pd.to_datetime(end_date)\n",
    "    total_days = max(1, (end - start).days)\n",
    "\n",
    "    # --- Helper maps for realistic keyword selection\n",
    "    kw_map = {\n",
    "        \"Auto\": [\"auto\", \"vehicle\", \"driver\", \"collision\", \"telematics\", \"premium\"],\n",
    "        \"Home\": [\"home\", \"property\", \"dwelling\", \"flood\", \"fire\", \"repair\", \"inspection\"],\n",
    "        \"Life\": [\"life\", \"beneficiary\", \"term\", \"payout\", \"underwriting\", \"medical\"],\n",
    "        \"Health\": [\"health\", \"hospital\", \"claim\", \"copay\", \"provider\", \"network\"],\n",
    "        \"General\": [\"renewal\", \"notice\", \"payment\", \"correspondence\", \"policy\", \"update\"],\n",
    "        \"Underwriting\": [\"risk\", \"score\", \"medical\", \"credit\", \"assessment\"],\n",
    "        \"CaseSummary\": [\"case\", \"resolution\", \"retention\", \"offer\", \"outcome\"],\n",
    "        \"Product\": [\"product\", \"plan\", \"feature\", \"tier\", \"update\", \"launch\"],\n",
    "        \"Marketing\": [\"campaign\", \"offer\", \"discount\", \"promotion\", \"customer\", \"communication\"],\n",
    "    }\n",
    "\n",
    "    # --- Base templates (policy, underwriting, product, marketing, etc.)\n",
    "    base_templates = [\n",
    "        (\"Auto\", \"Policy Wording\",\n",
    "         \"This Auto policy includes comprehensive, collision and liability coverages. Deductibles and premium adjustments depend on driver age, claim history, and telematics scores. {extra}\"),\n",
    "        (\"Home\", \"Policy Wording\",\n",
    "         \"This Home policy covers dwelling, personal property and loss-of-use. Coverage limits and exclusions depend on construction type and local hazards. {extra}\"),\n",
    "        (\"Life\", \"Policy Wording\",\n",
    "         \"Term and whole-life options are available. Premiums and eligibility depend on medical underwriting and beneficiary designation. {extra}\"),\n",
    "        (\"Health\", \"Policy Wording\",\n",
    "         \"Tiered health plans (Bronze/Silver/Gold) with varying provider networks and out-of-pocket limits. Pre-authorization required for selected services. {extra}\"),\n",
    "\n",
    "        (\"General\", \"Renewal Notice\",\n",
    "         \"Your policy is due for renewal on {policy_end_date}. Please review updated premium and coverage information. {extra}\"),\n",
    "        (\"General\", \"Premium Notice\",\n",
    "         \"We are notifying you of a premium change effective {effective_date} due to regional claim trends. {extra}\"),\n",
    "        (\"Underwriting\", \"Underwriting Note\",\n",
    "         \"Underwriting analysis: risk factors include {risk_factors}. Recommends class change: {recommendation}. {extra}\"),\n",
    "        (\"CaseSummary\", \"Retention Case\",\n",
    "         \"Case summary: Customer was at risk due to recent claims; retention offer included a targeted discount and service outreach. Outcome: {outcome}. {extra}\"),\n",
    "        (\"Product\", \"Product Update\",\n",
    "         \"Product update: New telematics discount launched. Eligible customers will receive communication and opt-in instructions. {extra}\"),\n",
    "        (\"General\", \"Claim Update\",\n",
    "         \"Claim {claim_ref} is being processed. Current status: {status}. Estimated settlement: {estimate}. {extra}\"),\n",
    "    ]\n",
    "\n",
    "    # --- Add new content types: Product Brochures & Campaign Templates\n",
    "    base_templates.extend([\n",
    "        (\"Product\", \"Brochure\",\n",
    "         \"Introducing our {policy_type} insurance plan — designed to provide better protection and flexible coverage options. Key highlights include: {highlights}. Learn how you can save with telematics and bundled discounts. {extra}\"),\n",
    "        (\"Product\", \"Product Overview\",\n",
    "         \"Our latest {policy_type} policy offers enhanced benefits, simplified claims, and faster online servicing. Whether you’re a new or existing customer, this plan helps you manage your coverage efficiently. {extra}\"),\n",
    "        (\"Marketing\", \"Campaign Template\",\n",
    "         \"Subject: {subject}\\n\\nDear customer, we’re excited to announce our new {policy_type} plan. {benefit_statement}. Don’t miss this opportunity — apply by {deadline}. {cta}\"),\n",
    "        (\"Marketing\", \"Email Campaign\",\n",
    "         \"Get rewarded for staying protected! Our loyalty campaign offers up to 15% off renewals on select {policy_type} policies. {extra} Join thousands who already switched and saved.\"),\n",
    "    ])\n",
    "\n",
    "    # --- Prepare synthetic linking to customers/policies if available\n",
    "    if customers_df is not None and \"policy_type\" in customers_df.columns:\n",
    "        customers_df = customers_df.copy()\n",
    "        if \"policy_id\" not in customers_df.columns:\n",
    "            customers_df[\"policy_id\"] = [f\"P{100000 + i}\" for i in range(len(customers_df))]\n",
    "        policy_links = customers_df[[\"customer_id\", \"policy_id\", \"policy_type\", \"policy_start_date\", \"policy_end_date\"]].to_dict(\"records\")\n",
    "    else:\n",
    "        policy_links = [{\"customer_id\": None, \"policy_id\": None, \"policy_type\": random.choice([\"Auto\",\"Home\",\"Life\",\"Health\"]),\n",
    "                         \"policy_start_date\": start + timedelta(days=random.randint(0, total_days//2)),\n",
    "                         \"policy_end_date\": start + timedelta(days=random.randint(total_days//2, total_days))} for _ in range(200)]\n",
    "\n",
    "    # --- Instantiate docs\n",
    "    all_docs = []\n",
    "    for (category, subtype, template) in base_templates:\n",
    "        for _ in range(3):  # multiple variants per template\n",
    "            extra_phrases = [\n",
    "                \"This language was updated to reflect regulatory guidance.\",\n",
    "                \"This clause applies only to new business issued within the last 12 months.\",\n",
    "                \"Refer to underwriting manual section 4.2 for scoring rules.\",\n",
    "                \"This summary reflects the current version of the product.\",\n",
    "            ]\n",
    "            extra = random.choice(extra_phrases)\n",
    "\n",
    "            safe_kwargs = dict(\n",
    "                extra=extra,\n",
    "                policy_type=random.choice([\"Auto\", \"Home\", \"Life\", \"Health\"]),\n",
    "                policy_end_date=\"2024-12-31\",\n",
    "                effective_date=\"2024-01-01\",\n",
    "                risk_factors=\"driver age, credit score\",\n",
    "                recommendation=\"standard\",\n",
    "                outcome=\"retained\",\n",
    "                claim_ref=f\"CLM{random.randint(10000,99999)}\",\n",
    "                status=\"in progress\",\n",
    "                estimate=\"$1500\",\n",
    "                highlights=random.choice([\n",
    "                    \"customizable deductibles, multi-policy savings, and digital servicing tools\",\n",
    "                    \"expanded coverage for extreme weather events and enhanced roadside assistance\",\n",
    "                    \"wellness rewards and lower premiums for safe drivers\",\n",
    "                ]),\n",
    "                subject=random.choice([\n",
    "                    \"Save More with Our New Plan!\",\n",
    "                    \"Exclusive Renewal Offer Inside\",\n",
    "                    \"Your Coverage, Upgraded\",\n",
    "                ]),\n",
    "                benefit_statement=random.choice([\n",
    "                    \"Enjoy lower premiums and smarter coverage options tailored to your needs\",\n",
    "                    \"Upgrade to enhanced protection with minimal paperwork\",\n",
    "                    \"Protect what matters most with our simplified digital policies\",\n",
    "                ]),\n",
    "                deadline=random.choice([\"June 30\", \"September 1\", \"December 31\"]),\n",
    "                cta=random.choice([\"Click here to learn more.\", \"Enroll today!\", \"Get your personalized quote now.\"]),\n",
    "            )\n",
    "\n",
    "            body = template.format(**safe_kwargs)\n",
    "            all_docs.append({\"category\": category, \"subtype\": subtype, \"text\": body})\n",
    "\n",
    "    # --- Expand if fewer than n_docs\n",
    "    while len(all_docs) < n_docs:\n",
    "        sample = random.choice(all_docs)\n",
    "        variation = sample.copy()\n",
    "        rev = random.randint(1, 5)\n",
    "        change = random.choice([\"Updated rates\", \"Coverage change\", \"New clause added\", \"Review summary\", \"Clarified exclusions\"])\n",
    "        variation[\"text\"] = f\"{variation['text']} (Revision {rev}: {change}).\"\n",
    "        all_docs.append(variation)\n",
    "\n",
    "    # --- Balanced sampling\n",
    "    if len(all_docs) > n_docs:\n",
    "        categories = list(set([d[\"category\"] for d in all_docs]))\n",
    "        chosen = []\n",
    "        for c in categories:\n",
    "            candidates = [d for d in all_docs if d[\"category\"] == c]\n",
    "            chosen.append(random.choice(candidates))\n",
    "        remaining = n_docs - len(chosen)\n",
    "        others = [d for d in all_docs if d not in chosen]\n",
    "        chosen.extend(random.sample(others, remaining))\n",
    "        all_docs = chosen\n",
    "\n",
    "    # --- Build final corpus with metadata and passage splitting\n",
    "    corpus = []\n",
    "    for i, doc in enumerate(all_docs, start=1):\n",
    "        uid = uuid.uuid4().hex[:8].upper()\n",
    "        doc_id = f\"DOC_{uid}\"\n",
    "        link = random.choice(policy_links)\n",
    "        linked_policy = link[\"policy_id\"] if random.random() < 0.4 else None\n",
    "        linked_customer = link[\"customer_id\"] if linked_policy is not None else None\n",
    "\n",
    "        if linked_policy and link.get(\"policy_start_date\") is not None and link.get(\"policy_end_date\") is not None:\n",
    "            p_start = pd.to_datetime(link[\"policy_start_date\"])\n",
    "            p_end = pd.to_datetime(link[\"policy_end_date\"])\n",
    "            if pd.isna(p_start) or pd.isna(p_end) or p_end <= p_start:\n",
    "                created_date = start + timedelta(days=random.randint(0, total_days))\n",
    "            else:\n",
    "                created_date = p_start + timedelta(days=random.randint(0, max(1, (p_end - p_start).days)))\n",
    "        else:\n",
    "            created_date = start + timedelta(days=random.randint(0, total_days))\n",
    "\n",
    "        source = \"internal\" if doc[\"subtype\"] in (\"Underwriting Note\", \"Agent Note\", \"CaseSummary\") else random.choice([\"customer-facing\", \"internal\", \"agent-note\"])\n",
    "        kw_pool = kw_map.get(doc[\"category\"], kw_map[\"General\"])\n",
    "        keywords = random.sample(kw_pool, k=min(len(kw_pool), random.randint(3, 5)))\n",
    "\n",
    "        context_sentences = [\n",
    "            \"This excerpt summarizes the key points relevant to pricing and retention.\",\n",
    "            \"Please refer to the full policy for exact conditions and exclusions.\",\n",
    "            \"Contact the underwriting or marketing team for clarifications.\",\n",
    "            \"This note was generated as part of an automated review process.\"\n",
    "        ]\n",
    "        text = doc[\"text\"] + \" \" + \" \".join(random.sample(context_sentences, k=random.randint(1, 2)))\n",
    "        text = shorten(text, width=800, placeholder=\" ...\")\n",
    "\n",
    "        words = text.split()\n",
    "        passages = [text] if len(words) <= max_passage_words else [\n",
    "            \" \".join(words[i:i+max_passage_words]) for i in range(0, len(words), max_passage_words)\n",
    "        ]\n",
    "\n",
    "        for p_idx, passage in enumerate(passages, start=1):\n",
    "            passage_id = f\"{doc_id}_P{p_idx:02d}\"\n",
    "            corpus.append({\n",
    "                \"doc_id\": doc_id,\n",
    "                \"passage_id\": passage_id,\n",
    "                \"policy_id\": linked_policy,\n",
    "                \"customer_id\": linked_customer,\n",
    "                \"category\": doc[\"category\"],\n",
    "                \"subtype\": doc[\"subtype\"],\n",
    "                \"source\": source,\n",
    "                \"created_date\": created_date,\n",
    "                \"created_date_str\": created_date.strftime(\"%Y-%m-%d\"),\n",
    "                \"text\": passage,\n",
    "                \"keywords\": keywords,\n",
    "            })\n",
    "\n",
    "    corpus_df = pd.DataFrame(corpus)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"✅ Generated document corpus: {len(corpus_df)} passages from {len(all_docs)} docs\")\n",
    "        print(f\"Categories: {sorted(corpus_df['category'].unique().tolist())}\")\n",
    "        print(\"Example passage metadata:\")\n",
    "        print(corpus_df.iloc[0].to_dict())\n",
    "\n",
    "    return corpus_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ad84ed-3e6f-4fb8-84ed-5d0e38e2e12f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
